{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport shutil\nfrom IPython.display import FileLink\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import SGDClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\n\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\nfrom transformers import TFAutoModelForSequenceClassification\nfrom transformers import AdamWeightDecay\nfrom datasets import Dataset, DatasetDict\n\nprint(tf.__version__)\nprint(tf.config.list_physical_devices())\n\n# startegy for training on multiple gpus\nmirrored_strategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:07.603895Z","iopub.execute_input":"2023-05-18T19:05:07.604375Z","iopub.status.idle":"2023-05-18T19:05:07.930309Z","shell.execute_reply.started":"2023-05-18T19:05:07.604333Z","shell.execute_reply":"2023-05-18T19:05:07.929232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('../input/edos-1m/EDOS 1M.csv')\ndataset_percentage = 0.3\ndataset = dataset.sample(n=int(len(dataset)*dataset_percentage))\n\nX,y = dataset[\"uttr\"], dataset[\"eb+_emot\"]\n\nprint(X.head(5))\nprint(type(X), end=\"\\n\\n\")\nprint(y.head(5))\nprint(type(y), end=\"\\n\\n\")\n\nclasses = y.unique()\nclasses","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:07.932561Z","iopub.execute_input":"2023-05-18T19:05:07.933226Z","iopub.status.idle":"2023-05-18T19:05:17.390389Z","shell.execute_reply.started":"2023-05-18T19:05:07.933192Z","shell.execute_reply":"2023-05-18T19:05:17.389310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"# plot classes distribution\ncounts = pd.get_dummies(y).sum()\n\nplt.ylabel('Counts')\nplt.xlabel('Classes')\nsns.barplot(x = [i for i in range(len(classes))], y = counts)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:17.391867Z","iopub.execute_input":"2023-05-18T19:05:17.392615Z","iopub.status.idle":"2023-05-18T19:05:18.231105Z","shell.execute_reply.started":"2023-05-18T19:05:17.392581Z","shell.execute_reply":"2023-05-18T19:05:18.230156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, validation and test split\ntrain_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.2)\n\nprint(\"train size: \", len(train_X))\nprint(\"validation size: \", len(valid_X))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:18.233869Z","iopub.execute_input":"2023-05-18T19:05:18.235277Z","iopub.status.idle":"2023-05-18T19:05:18.473726Z","shell.execute_reply.started":"2023-05-18T19:05:18.235240Z","shell.execute_reply":"2023-05-18T19:05:18.472693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Single utterance classification - Baseline model","metadata":{}},{"cell_type":"code","source":"# vectorize the text using word count\nvectorizer = CountVectorizer(min_df=5, stop_words='english')\nvectorizer.fit(train_X)\nprint(\"Vocabulary length: \" + str(len(vectorizer.get_feature_names_out())))\nprint(\"First words: \" + str(vectorizer.get_feature_names_out()[:200]))\n\ntrain_X_vector = vectorizer.transform(train_X)\nvalid_X_vector = vectorizer.transform(valid_X)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:18.475190Z","iopub.execute_input":"2023-05-18T19:05:18.477189Z","iopub.status.idle":"2023-05-18T19:05:40.603232Z","shell.execute_reply.started":"2023-05-18T19:05:18.477152Z","shell.execute_reply":"2023-05-18T19:05:40.602182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# going for SVMs since they're usually reliable with high dimensional data\nmodel = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-5, max_iter=5, tol=None)\nmodel.fit(train_X_vector, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:05:40.604525Z","iopub.execute_input":"2023-05-18T19:05:40.604902Z","iopub.status.idle":"2023-05-18T19:06:07.604911Z","shell.execute_reply.started":"2023-05-18T19:05:40.604868Z","shell.execute_reply":"2023-05-18T19:06:07.603848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validate the model\npred_y = model.predict(valid_X_vector)\n\nprint('Results for the basic SVM classifier:')\nprint(classification_report(valid_y, pred_y, target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:07.606420Z","iopub.execute_input":"2023-05-18T19:06:07.606759Z","iopub.status.idle":"2023-05-18T19:06:15.645181Z","shell.execute_reply.started":"2023-05-18T19:06:07.606726Z","shell.execute_reply":"2023-05-18T19:06:15.644219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Single utterance classification - Transformer-based model","metadata":{}},{"cell_type":"code","source":"# model metadata\nmodel_name = \"distilbert-base-uncased\"\n\n# map expected ids to their labels and viceversa\nid2label = dict(zip(range(len(classes)), classes))\nlabel2id = dict(zip(classes, range(len(classes))))\nid2label","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:15.649661Z","iopub.execute_input":"2023-05-18T19:06:15.652394Z","iopub.status.idle":"2023-05-18T19:06:15.665676Z","shell.execute_reply.started":"2023-05-18T19:06:15.652357Z","shell.execute_reply":"2023-05-18T19:06:15.664862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building the datasets\ntrain_data = Dataset.from_pandas(pd.DataFrame({\"text\": train_X, \"label\": np.argmax(pd.get_dummies(train_y).to_numpy(), axis=1)}), preserve_index=False)\nvalid_data = Dataset.from_pandas(pd.DataFrame({\"text\": valid_X, \"label\": np.argmax(pd.get_dummies(valid_y).to_numpy(), axis=1)}), preserve_index=False)\n\n# shuffling is performed at the previous operation -> we need to redefine valid_y\nvalid_y = valid_data['label']\n\ndata = DatasetDict()\ndata['train'] = train_data\ndata['validation'] = valid_data\n\nprint(data['train'][0])\ndata","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:15.670742Z","iopub.execute_input":"2023-05-18T19:06:15.673454Z","iopub.status.idle":"2023-05-18T19:06:16.595728Z","shell.execute_reply.started":"2023-05-18T19:06:15.673416Z","shell.execute_reply":"2023-05-18T19:06:16.594804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# tokenize the data\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\ntokenized_data = data.map(preprocess_function, batched=True)\n\nprint(tokenized_data[\"train\"][0])\ntokenized_data","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:06:16.599155Z","iopub.execute_input":"2023-05-18T19:06:16.600171Z","iopub.status.idle":"2023-05-18T19:07:19.767821Z","shell.execute_reply.started":"2023-05-18T19:06:16.600134Z","shell.execute_reply":"2023-05-18T19:07:19.766973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metadata\nbatch_size = 16\nnum_epochs = 20\npatience = 3\nonly_fine_tune = True\n\n# convert datasets to a suitable format for tensorflow\ndata_collator = DataCollatorWithPadding(tokenizer, return_tensors=\"tf\")\n\ntf_train_dataset = tokenized_data[\"train\"].to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n    shuffle=True,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n)\n\ntf_validation_dataset = tokenized_data[\"validation\"].to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n    shuffle=False,\n    batch_size=batch_size,\n    collate_fn=data_collator,\n)\n\n# create optimizer and learning rate scheduler\nnum_train_steps = len(tf_train_dataset) * num_epochs\nlr_scheduler = PolynomialDecay(\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n)\nopt = AdamWeightDecay(learning_rate=lr_scheduler,\n                      weight_decay_rate=0.01)\n\n# from within the selected parallelization strategy...\nwith mirrored_strategy.scope():\n    \n    # ...load the model...\n    model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(classes), id2label=id2label, label2id=label2id)\n    if only_fine_tune:\n        for i in range(1):\n            model.layers[i].trainable = False\n    \n    # ...and compile it\n    model.compile(optimizer=opt,\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  metrics=[\"accuracy\"])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:07:19.772334Z","iopub.execute_input":"2023-05-18T19:07:19.774641Z","iopub.status.idle":"2023-05-18T19:07:28.300304Z","shell.execute_reply.started":"2023-05-18T19:07:19.774606Z","shell.execute_reply":"2023-05-18T19:07:28.299337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training\nhistory = model.fit(\n          tf_train_dataset,\n          validation_data=tf_validation_dataset,\n          epochs=num_epochs,                                  \n          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=patience, restore_best_weights=True)]\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:07:28.302038Z","iopub.execute_input":"2023-05-18T19:07:28.302722Z","iopub.status.idle":"2023-05-18T19:08:42.684460Z","shell.execute_reply.started":"2023-05-18T19:07:28.302687Z","shell.execute_reply":"2023-05-18T19:08:42.682207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validate the model -> accuracy should correspond to final val_accuracy\nbert_y = np.argmax(model.predict(tf_validation_dataset)[\"logits\"], axis=1)\n\nprint('Results for BERT-based classifier:')\nprint(classification_report(valid_y, bert_y, target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:08:47.035478Z","iopub.execute_input":"2023-05-18T19:08:47.035852Z","iopub.status.idle":"2023-05-18T19:15:42.426716Z","shell.execute_reply.started":"2023-05-18T19:08:47.035818Z","shell.execute_reply":"2023-05-18T19:15:42.425614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('bert_model')\nshutil.make_archive('bert_model', 'zip', 'bert_model')\nFileLink(r'bert_model.zip')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T19:16:48.063995Z","iopub.execute_input":"2023-05-18T19:16:48.064344Z","iopub.status.idle":"2023-05-18T19:17:21.943792Z","shell.execute_reply.started":"2023-05-18T19:16:48.064314Z","shell.execute_reply":"2023-05-18T19:17:21.942622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}