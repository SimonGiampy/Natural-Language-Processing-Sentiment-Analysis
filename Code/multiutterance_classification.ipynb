{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import SGDClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers.schedules import PolynomialDecay\n\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\nfrom transformers import TFAutoModelForSequenceClassification\nfrom transformers import AdamWeightDecay\nfrom datasets import Dataset, DatasetDict\n\nprint(tf.__version__)\nprint(tf.config.list_physical_devices())\n\n# startegy for training on multiple gpus\nmirrored_strategy = tf.distribute.MirroredStrategy()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:10:44.045003Z","iopub.execute_input":"2023-05-18T10:10:44.045541Z","iopub.status.idle":"2023-05-18T10:10:44.060522Z","shell.execute_reply.started":"2023-05-18T10:10:44.045495Z","shell.execute_reply":"2023-05-18T10:10:44.059308Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"2.11.0\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/edos-1m/\"\n\ndataset = pd.read_csv(path + \"EDOS 1M.csv\")\ndataset = dataset.head(10000)\nclasses = dataset[\"eb+_emot\"].unique()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-18T10:10:44.063186Z","iopub.execute_input":"2023-05-18T10:10:44.063640Z","iopub.status.idle":"2023-05-18T10:10:51.965643Z","shell.execute_reply.started":"2023-05-18T10:10:44.063585Z","shell.execute_reply":"2023-05-18T10:10:51.964317Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"#preparing the new dataset containing utterances pairs\n\ndf = dataset.merge(dataset, on='dialogue_id', how='inner') #self join\n#creating auxialiary attributes\ndf['is_first'] = (df['turn_x'] == 1) & (df['turn_y'] == 1)\ndf['is_last'] = (df['turn_x'] == df['turn_y']) & (df['turn_y'] == df.groupby('dialogue_id')['turn_y'].transform(max))\n#keep only first/last utterances and all the consecutive pairs               \ndf = df[df['is_first'] | df['is_last'] | (df['turn_x'] == df['turn_y'] - 1)]\n#display(df,10) \n\n#df_preceding will be used to predict the last utterance, given the previous context, if it exists\ndf_preceding = df[df['is_last'] == 0]\ndf_preceding = df_preceding[['dialogue_id','turn_x','uttr_x','turn_y','uttr_y','eb+_emot_y','is_first']].rename(columns={'eb+_emot_y': 'label'})\n#df_following will be used to predict the first utterance, given the following context, if it exists\ndf_following = df[df['is_first'] == 0]\ndf_following = df_following[['dialogue_id','turn_x','uttr_x','turn_y','uttr_y','eb+_emot_x','is_last']].rename(columns={'eb+_emot_x': 'label'})\n\ndisplay(df_preceding,10)\ndisplay(df_following,10)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:11:29.079707Z","iopub.execute_input":"2023-05-18T10:11:29.080162Z","iopub.status.idle":"2023-05-18T10:11:29.166788Z","shell.execute_reply.started":"2023-05-18T10:11:29.080127Z","shell.execute_reply":"2023-05-18T10:11:29.165445Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"       dialogue_id  turn_x                                             uttr_x  \\\n0               97       1  You moron ! What fool washes diapers by the we...   \n1               97       1  You moron ! What fool washes diapers by the we...   \n4               99       1                               How dare you sleep !   \n5               99       1                               How dare you sleep !   \n8              100       1                                Clean the kitchen .   \n...            ...     ...                                                ...   \n27758       213856       2  I love the water . I miss the water . When tha...   \n27764       213856       3         Diamond rose \" ? I thought it was \" jinx .   \n27770       213856       4                         Anyway , you were saying ?   \n27776       214055       1  Maybe now you can tell us what 's going on . T...   \n27777       214055       1  Maybe now you can tell us what 's going on . T...   \n\n       turn_y                                             uttr_y        label  \\\n0           1  You moron ! What fool washes diapers by the we...        angry   \n1           2                                 You useless fool !      furious   \n4           1                               How dare you sleep !      furious   \n5           2                      Up ! Go and clean the house .     prepared   \n8           1                                Clean the kitchen .     prepared   \n...       ...                                                ...          ...   \n27758       3         Diamond rose \" ? I thought it was \" jinx .    surprised   \n27764       4                         Anyway , you were saying ?  questioning   \n27770       5  Oh , I-I grew up on the water , imagining I 'd...    nostalgic   \n27776       1  Maybe now you can tell us what 's going on . T...      hopeful   \n27777       2  273 ) } – What contagion ? – My wife didn 't g...          sad   \n\n       is_first  \n0          True  \n1         False  \n4          True  \n5         False  \n8          True  \n...         ...  \n27758     False  \n27764     False  \n27770     False  \n27776      True  \n27777     False  \n\n[10000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialogue_id</th>\n      <th>turn_x</th>\n      <th>uttr_x</th>\n      <th>turn_y</th>\n      <th>uttr_y</th>\n      <th>label</th>\n      <th>is_first</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>angry</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>97</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>2</td>\n      <td>You useless fool !</td>\n      <td>furious</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>furious</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>99</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>2</td>\n      <td>Up ! Go and clean the house .</td>\n      <td>prepared</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100</td>\n      <td>1</td>\n      <td>Clean the kitchen .</td>\n      <td>1</td>\n      <td>Clean the kitchen .</td>\n      <td>prepared</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27758</th>\n      <td>213856</td>\n      <td>2</td>\n      <td>I love the water . I miss the water . When tha...</td>\n      <td>3</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>surprised</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27764</th>\n      <td>213856</td>\n      <td>3</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>4</td>\n      <td>Anyway , you were saying ?</td>\n      <td>questioning</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27770</th>\n      <td>213856</td>\n      <td>4</td>\n      <td>Anyway , you were saying ?</td>\n      <td>5</td>\n      <td>Oh , I-I grew up on the water , imagining I 'd...</td>\n      <td>nostalgic</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27776</th>\n      <td>214055</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>hopeful</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27777</th>\n      <td>214055</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>2</td>\n      <td>273 ) } – What contagion ? – My wife didn 't g...</td>\n      <td>sad</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 7 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"10"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       dialogue_id  turn_x                                             uttr_x  \\\n0               97       1  You moron ! What fool washes diapers by the we...   \n1               97       1  You moron ! What fool washes diapers by the we...   \n4               99       1                               How dare you sleep !   \n5               99       1                               How dare you sleep !   \n8              100       1                                Clean the kitchen .   \n...            ...     ...                                                ...   \n27758       213856       2  I love the water . I miss the water . When tha...   \n27764       213856       3         Diamond rose \" ? I thought it was \" jinx .   \n27770       213856       4                         Anyway , you were saying ?   \n27776       214055       1  Maybe now you can tell us what 's going on . T...   \n27777       214055       1  Maybe now you can tell us what 's going on . T...   \n\n       turn_y                                             uttr_y        label  \\\n0           1  You moron ! What fool washes diapers by the we...        angry   \n1           2                                 You useless fool !      furious   \n4           1                               How dare you sleep !      furious   \n5           2                      Up ! Go and clean the house .     prepared   \n8           1                                Clean the kitchen .     prepared   \n...       ...                                                ...          ...   \n27758       3         Diamond rose \" ? I thought it was \" jinx .    surprised   \n27764       4                         Anyway , you were saying ?  questioning   \n27770       5  Oh , I-I grew up on the water , imagining I 'd...    nostalgic   \n27776       1  Maybe now you can tell us what 's going on . T...      hopeful   \n27777       2  273 ) } – What contagion ? – My wife didn 't g...          sad   \n\n       is_first  \n0          True  \n1         False  \n4          True  \n5         False  \n8          True  \n...         ...  \n27758     False  \n27764     False  \n27770     False  \n27776      True  \n27777     False  \n\n[10000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialogue_id</th>\n      <th>turn_x</th>\n      <th>uttr_x</th>\n      <th>turn_y</th>\n      <th>uttr_y</th>\n      <th>label</th>\n      <th>is_first</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>97</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>angry</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>97</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>2</td>\n      <td>You useless fool !</td>\n      <td>furious</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>99</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>furious</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>99</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>2</td>\n      <td>Up ! Go and clean the house .</td>\n      <td>prepared</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100</td>\n      <td>1</td>\n      <td>Clean the kitchen .</td>\n      <td>1</td>\n      <td>Clean the kitchen .</td>\n      <td>prepared</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27758</th>\n      <td>213856</td>\n      <td>2</td>\n      <td>I love the water . I miss the water . When tha...</td>\n      <td>3</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>surprised</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27764</th>\n      <td>213856</td>\n      <td>3</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>4</td>\n      <td>Anyway , you were saying ?</td>\n      <td>questioning</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27770</th>\n      <td>213856</td>\n      <td>4</td>\n      <td>Anyway , you were saying ?</td>\n      <td>5</td>\n      <td>Oh , I-I grew up on the water , imagining I 'd...</td>\n      <td>nostalgic</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27776</th>\n      <td>214055</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>hopeful</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27777</th>\n      <td>214055</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>2</td>\n      <td>273 ) } – What contagion ? – My wife didn 't g...</td>\n      <td>sad</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 7 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"10"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       dialogue_id  turn_x                                             uttr_x  \\\n1               97       1  You moron ! What fool washes diapers by the we...   \n3               97       2                                 You useless fool !   \n5               99       1                               How dare you sleep !   \n7               99       2                      Up ! Go and clean the house .   \n9              100       1                                Clean the kitchen .   \n...            ...     ...                                                ...   \n27764       213856       3         Diamond rose \" ? I thought it was \" jinx .   \n27770       213856       4                         Anyway , you were saying ?   \n27775       213856       5  Oh , I-I grew up on the water , imagining I 'd...   \n27777       214055       1  Maybe now you can tell us what 's going on . T...   \n27779       214055       2  273 ) } – What contagion ? – My wife didn 't g...   \n\n       turn_y                                             uttr_y        label  \\\n1           2                                 You useless fool !        angry   \n3           2                                 You useless fool !      furious   \n5           2                      Up ! Go and clean the house .      furious   \n7           2                      Up ! Go and clean the house .     prepared   \n9           2                   I cleaned the kitchen , ma 'am .     prepared   \n...       ...                                                ...          ...   \n27764       4                         Anyway , you were saying ?    surprised   \n27770       5  Oh , I-I grew up on the water , imagining I 'd...  questioning   \n27775       5  Oh , I-I grew up on the water , imagining I 'd...    nostalgic   \n27777       2  273 ) } – What contagion ? – My wife didn 't g...      hopeful   \n27779       2  273 ) } – What contagion ? – My wife didn 't g...          sad   \n\n       is_last  \n1        False  \n3         True  \n5        False  \n7         True  \n9        False  \n...        ...  \n27764    False  \n27770    False  \n27775     True  \n27777    False  \n27779     True  \n\n[10000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialogue_id</th>\n      <th>turn_x</th>\n      <th>uttr_x</th>\n      <th>turn_y</th>\n      <th>uttr_y</th>\n      <th>label</th>\n      <th>is_last</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>97</td>\n      <td>1</td>\n      <td>You moron ! What fool washes diapers by the we...</td>\n      <td>2</td>\n      <td>You useless fool !</td>\n      <td>angry</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>97</td>\n      <td>2</td>\n      <td>You useless fool !</td>\n      <td>2</td>\n      <td>You useless fool !</td>\n      <td>furious</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>99</td>\n      <td>1</td>\n      <td>How dare you sleep !</td>\n      <td>2</td>\n      <td>Up ! Go and clean the house .</td>\n      <td>furious</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>99</td>\n      <td>2</td>\n      <td>Up ! Go and clean the house .</td>\n      <td>2</td>\n      <td>Up ! Go and clean the house .</td>\n      <td>prepared</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100</td>\n      <td>1</td>\n      <td>Clean the kitchen .</td>\n      <td>2</td>\n      <td>I cleaned the kitchen , ma 'am .</td>\n      <td>prepared</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27764</th>\n      <td>213856</td>\n      <td>3</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>4</td>\n      <td>Anyway , you were saying ?</td>\n      <td>surprised</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27770</th>\n      <td>213856</td>\n      <td>4</td>\n      <td>Anyway , you were saying ?</td>\n      <td>5</td>\n      <td>Oh , I-I grew up on the water , imagining I 'd...</td>\n      <td>questioning</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27775</th>\n      <td>213856</td>\n      <td>5</td>\n      <td>Oh , I-I grew up on the water , imagining I 'd...</td>\n      <td>5</td>\n      <td>Oh , I-I grew up on the water , imagining I 'd...</td>\n      <td>nostalgic</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27777</th>\n      <td>214055</td>\n      <td>1</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>2</td>\n      <td>273 ) } – What contagion ? – My wife didn 't g...</td>\n      <td>hopeful</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27779</th>\n      <td>214055</td>\n      <td>2</td>\n      <td>273 ) } – What contagion ? – My wife didn 't g...</td>\n      <td>2</td>\n      <td>273 ) } – What contagion ? – My wife didn 't g...</td>\n      <td>sad</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 7 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"df_choice = 0 #0 for preceding, 1 for following\n# train, validation and test split\nif df_choice == 0:\n    df = df_preceding\n    train_X, valid_X, train_y, valid_y = train_test_split(df[['dialogue_id','uttr_x','uttr_y','is_first']], df['label'], test_size=0.15, stratify= None, shuffle=False)\nelse:\n    df = df_following\n    train_X, valid_X, train_y, valid_y = train_test_split(df[['dialogue_id','uttr_x','uttr_y','is_last']], df['label'], test_size=0.15, stratify= None, shuffle=False)\n\nclasses = df['label'].unique()\nprint(len(classes))\n\ndisplay(valid_X,10)\nprint(\"train size: \", len(train_X))\nprint(\"validation size: \", len(valid_X))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:20:49.267919Z","iopub.execute_input":"2023-05-18T10:20:49.268936Z","iopub.status.idle":"2023-05-18T10:20:49.299377Z","shell.execute_reply.started":"2023-05-18T10:20:49.268871Z","shell.execute_reply":"2023-05-18T10:20:49.297852Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"41\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       dialogue_id                                             uttr_x  \\\n23494       184152  Can I help you ? I have to visit Thomas Burton...   \n23495       184152  Can I help you ? I have to visit Thomas Burton...   \n23498       184297  The poor fellow thinks he was in love . A wret...   \n23499       184297  The poor fellow thinks he was in love . A wret...   \n23502       184328                         Nice to be back in Italy .   \n...            ...                                                ...   \n27758       213856  I love the water . I miss the water . When tha...   \n27764       213856         Diamond rose \" ? I thought it was \" jinx .   \n27770       213856                         Anyway , you were saying ?   \n27776       214055  Maybe now you can tell us what 's going on . T...   \n27777       214055  Maybe now you can tell us what 's going on . T...   \n\n                                                  uttr_y  is_first  \n23494  Can I help you ? I have to visit Thomas Burton...      True  \n23495  Hello , I 'm dr . Rockwell . Your uncle is my ...     False  \n23498  The poor fellow thinks he was in love . A wret...      True  \n23499  And who is the object of his desire A young , ...     False  \n23502                         Nice to be back in Italy .      True  \n...                                                  ...       ...  \n27758         Diamond rose \" ? I thought it was \" jinx .     False  \n27764                         Anyway , you were saying ?     False  \n27770  Oh , I-I grew up on the water , imagining I 'd...     False  \n27776  Maybe now you can tell us what 's going on . T...      True  \n27777  273 ) } – What contagion ? – My wife didn 't g...     False  \n\n[1500 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialogue_id</th>\n      <th>uttr_x</th>\n      <th>uttr_y</th>\n      <th>is_first</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23494</th>\n      <td>184152</td>\n      <td>Can I help you ? I have to visit Thomas Burton...</td>\n      <td>Can I help you ? I have to visit Thomas Burton...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23495</th>\n      <td>184152</td>\n      <td>Can I help you ? I have to visit Thomas Burton...</td>\n      <td>Hello , I 'm dr . Rockwell . Your uncle is my ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>23498</th>\n      <td>184297</td>\n      <td>The poor fellow thinks he was in love . A wret...</td>\n      <td>The poor fellow thinks he was in love . A wret...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23499</th>\n      <td>184297</td>\n      <td>The poor fellow thinks he was in love . A wret...</td>\n      <td>And who is the object of his desire A young , ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>23502</th>\n      <td>184328</td>\n      <td>Nice to be back in Italy .</td>\n      <td>Nice to be back in Italy .</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27758</th>\n      <td>213856</td>\n      <td>I love the water . I miss the water . When tha...</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27764</th>\n      <td>213856</td>\n      <td>Diamond rose \" ? I thought it was \" jinx .</td>\n      <td>Anyway , you were saying ?</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27770</th>\n      <td>213856</td>\n      <td>Anyway , you were saying ?</td>\n      <td>Oh , I-I grew up on the water , imagining I 'd...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>27776</th>\n      <td>214055</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27777</th>\n      <td>214055</td>\n      <td>Maybe now you can tell us what 's going on . T...</td>\n      <td>273 ) } – What contagion ? – My wife didn 't g...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 4 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"10"},"metadata":{}},{"name":"stdout","text":"train size:  8500\nvalidation size:  1500\n","output_type":"stream"}]},{"cell_type":"code","source":"# model metadata\nmodel_name = \"distilbert-base-uncased\"\n# map expected ids to their labels and viceversa\nid2label = dict(zip(range(len(classes)), classes))\nlabel2id = dict(zip(classes, range(len(classes))))\nid2label\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:24:17.102595Z","iopub.execute_input":"2023-05-18T10:24:17.103015Z","iopub.status.idle":"2023-05-18T10:24:17.112215Z","shell.execute_reply.started":"2023-05-18T10:24:17.102982Z","shell.execute_reply":"2023-05-18T10:24:17.111479Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"{0: 'angry',\n 1: 'furious',\n 2: 'prepared',\n 3: 'acknowledging',\n 4: 'trusting',\n 5: 'confident',\n 6: 'hopeful',\n 7: 'caring',\n 8: 'sentimental',\n 9: 'anticipating',\n 10: 'wishing',\n 11: 'surprised',\n 12: 'ashamed',\n 13: 'questioning',\n 14: 'sad',\n 15: 'nostalgic',\n 16: 'devastated',\n 17: 'terrified',\n 18: 'embarrassed',\n 19: 'lonely',\n 20: 'encouraging',\n 21: 'suggesting',\n 22: 'content',\n 23: 'afraid',\n 24: 'impressed',\n 25: 'agreeing',\n 26: 'apprehensive',\n 27: 'proud',\n 28: 'annoyed',\n 29: 'anxious',\n 30: 'grateful',\n 31: 'excited',\n 32: 'neutral',\n 33: 'faithful',\n 34: 'guilty',\n 35: 'consoling',\n 36: 'disgusted',\n 37: 'disappointed',\n 38: 'jealous',\n 39: 'joyful',\n 40: 'sympathizing'}"},"metadata":{}}]},{"cell_type":"code","source":"# building the datasets\nif df_choice == 0:\n    flag = \"is_first\"\nelse:\n    flag= \"is_last\"\ntrain_data = Dataset.from_pandas(pd.DataFrame({\"text_1\": train_X['uttr_x'],\"text_2\": train_X['uttr_y'], flag: train_X[flag], \"label\": np.argmax(pd.get_dummies(train_y).to_numpy(), axis=1)}), preserve_index=False)\nvalid_data = Dataset.from_pandas(pd.DataFrame({\"text_1\": valid_X['uttr_x'],\"text_2\": valid_X['uttr_y'], flag: valid_X[flag], \"label\": np.argmax(pd.get_dummies(valid_y).to_numpy(), axis=1)}), preserve_index=False)\n\n# shuffling is performed at the previous operation -> we need to redefine valid_y\nvalid_y = valid_data['label']\n\ndata = DatasetDict()\ndata['train'] = train_data\ndata['validation'] = valid_data\n\nprint(data['train'][0])\ndata","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:30:18.706448Z","iopub.execute_input":"2023-05-18T10:30:18.706852Z","iopub.status.idle":"2023-05-18T10:30:18.744699Z","shell.execute_reply.started":"2023-05-18T10:30:18.706821Z","shell.execute_reply":"2023-05-18T10:30:18.743788Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"{'text_1': 'You moron ! What fool washes diapers by the well !', 'text_2': 'You moron ! What fool washes diapers by the well !', 'is_first': True, 'label': 3}\n","output_type":"stream"},{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text_1', 'text_2', 'is_first', 'label'],\n        num_rows: 8500\n    })\n    validation: Dataset({\n        features: ['text_1', 'text_2', 'is_first', 'label'],\n        num_rows: 1500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# tokenize the data\ndef preprocess_function(examples):\n    if df_choice == 0:\n        if examples[\"is_first\"]:\n            return tokenizer([\"\",examples[\"text_2\"]], truncation=True)\n        else:\n            return tokenizer([examples[\"text_1\"],examples[\"text_2\"]], truncation=True)\n    else:\n        if examples[\"is_last\"]:\n            return tokenizer([examples[\"text_1\"],\"\"], truncation=True)\n        else:\n            return tokenizer([examples[\"text_1\"],examples[\"text_2\"]], truncation=True)\n\ntokenized_data = data.map(preprocess_function, batched=True)\n\nprint(tokenized_data[\"train\"][0])\ntokenized_data","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:43:20.363499Z","iopub.execute_input":"2023-05-18T10:43:20.364032Z","iopub.status.idle":"2023-05-18T10:43:21.197421Z","shell.execute_reply.started":"2023-05-18T10:43:20.363996Z","shell.execute_reply":"2023-05-18T10:43:21.193352Z"},"trusted":true},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8aca6853d440b9b60aaf14a8df1e09"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[101], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer([examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_1\u001b[39m\u001b[38;5;124m\"\u001b[39m],examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]], truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m tokenized_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenized_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     20\u001b[0m tokenized_data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/dataset_dict.py:438\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 438\u001b[0m     {\n\u001b[1;32m    439\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    440\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    441\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    442\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    443\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    444\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    445\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    446\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    447\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    448\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    449\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    450\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    451\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    452\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    453\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    454\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    455\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    456\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    457\u001b[0m         )\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    459\u001b[0m     }\n\u001b[1;32m    460\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/dataset_dict.py:439\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    438\u001b[0m     {\n\u001b[0;32m--> 439\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    459\u001b[0m     }\n\u001b[1;32m    460\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1955\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   1952\u001b[0m disable_tqdm \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_proc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1977\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:520\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:487\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    485\u001b[0m }\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/fingerprint.py:458\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             kwargs[fingerprint_name] \u001b[38;5;241m=\u001b[39m update_fingerprint(\n\u001b[1;32m    453\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[1;32m    454\u001b[0m             )\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2339\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2335\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(input_dataset\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   2337\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2339\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2348\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:2220\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   2219\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 2220\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2223\u001b[0m     update_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[38;5;241m.\u001b[39mTable))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1915\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1911\u001b[0m decorated_item \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1912\u001b[0m     Example(item, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched \u001b[38;5;28;01melse\u001b[39;00m Batch(item, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m   1913\u001b[0m )\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;66;03m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> 1915\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorated_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, LazyDict) \u001b[38;5;28;01melse\u001b[39;00m result\n","Cell \u001b[0;32mIn[101], line 8\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_first\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer([examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_1\u001b[39m\u001b[38;5;124m\"\u001b[39m],examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]], truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2538\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2537\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2538\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2624\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2619\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2620\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2621\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2622\u001b[0m         )\n\u001b[1;32m   2623\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2645\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2646\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2662\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2663\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2815\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2806\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2807\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2808\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2812\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2813\u001b[0m )\n\u001b[0;32m-> 2815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:428\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    421\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    422\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    426\u001b[0m )\n\u001b[0;32m--> 428\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    440\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    442\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    452\u001b[0m ]\n","\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"],"ename":"TypeError","evalue":"TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]","output_type":"error"}]},{"cell_type":"code","source":"#testing the tokenizer\nbatch_sentences = [\n    \"UTTR_X\",\n    \"UTTR_Y\",\n]\n\nencoded_dict = tokenizer([batch_sentences])\n#decoded = tokenizer.decode(encoded_dict[\"input_ids\"])\n#print(decoded)\nprint(encoded_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:10:52.276869Z","iopub.execute_input":"2023-05-18T10:10:52.277208Z","iopub.status.idle":"2023-05-18T10:10:52.284803Z","shell.execute_reply.started":"2023-05-18T10:10:52.277179Z","shell.execute_reply":"2023-05-18T10:10:52.283474Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"{'input_ids': [[101, 21183, 16344, 1035, 1060, 102, 21183, 16344, 1035, 1061, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"}]}]}