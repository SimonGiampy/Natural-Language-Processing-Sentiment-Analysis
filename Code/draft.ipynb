{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>turn</th>\n",
       "      <th>uttr</th>\n",
       "      <th>eb+_emot</th>\n",
       "      <th>label_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>You moron ! What fool washes diapers by the we...</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.437522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>You useless fool !</td>\n",
       "      <td>furious</td>\n",
       "      <td>0.731564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>How dare you sleep !</td>\n",
       "      <td>furious</td>\n",
       "      <td>0.605636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>Up ! Go and clean the house .</td>\n",
       "      <td>prepared</td>\n",
       "      <td>0.650449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>Clean the kitchen .</td>\n",
       "      <td>prepared</td>\n",
       "      <td>0.742187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialogue_id  turn                                               uttr  \\\n",
       "0           97     1  You moron ! What fool washes diapers by the we...   \n",
       "1           97     2                                 You useless fool !   \n",
       "2           99     1                               How dare you sleep !   \n",
       "3           99     2                      Up ! Go and clean the house .   \n",
       "4          100     1                                Clean the kitchen .   \n",
       "\n",
       "   eb+_emot  label_confidence  \n",
       "0     angry          0.437522  \n",
       "1   furious          0.731564  \n",
       "2   furious          0.605636  \n",
       "3  prepared          0.650449  \n",
       "4  prepared          0.742187  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../Dataset/EDOS 1M.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    You moron ! What fool washes diapers by the we...\n",
      "1                                   You useless fool !\n",
      "2                                 How dare you sleep !\n",
      "3                        Up ! Go and clean the house .\n",
      "4                                  Clean the kitchen .\n",
      "Name: uttr, dtype: object\n",
      "0       angry\n",
      "1     furious\n",
      "2     furious\n",
      "3    prepared\n",
      "4    prepared\n",
      "Name: eb+_emot, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X,y = dataset[\"uttr\"], dataset[\"eb+_emot\"]\n",
    "print(X.head(5))\n",
    "print(y.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: one-hot encode train_y and eventually find a way to correct OCR errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_test_X, test_X, no_test_y, test_y = train_test_split(X, y, test_size=0.15)\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(no_test_X, no_test_y, test_size=0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single utterance classification - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 32067\n",
      "Most common words: ['00' '000' '007' '00am' '01' '02' '03' '04' '05' '06' '0600' '07' '08'\n",
      " '0800' '09' '0f' '0h' '0k' '0n' '0ne' '0r' '0ur' '10' '100' '1000'\n",
      " '10000' '100th' '101' '102' '103' '104' '105' '106' '107' '108' '109'\n",
      " '10am' '10s' '10th' '11' '110' '1100' '111' '112' '113' '114' '115' '116'\n",
      " '117' '118' '119' '11th' '12' '120' '1200' '121' '123' '125' '128' '12th'\n",
      " '13' '130' '1300' '132' '135' '13th' '14' '140' '1400' '143' '147' '14th'\n",
      " '15' '150' '1500' '155' '156' '15th' '16' '160' '1600' '16th' '17' '170'\n",
      " '1700' '175' '17th' '18' '180' '1800' '1800s' '185' '1890' '18th' '19'\n",
      " '1900' '1914' '1917' '1918' '1920']\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text using word count\n",
    "vectorizer = CountVectorizer(min_df=10, stop_words='english') #TODO: try without stopwords\n",
    "vectorizer.fit(train_X)\n",
    "print(\"Vocabulary length: \"+str(len(vectorizer.get_feature_names_out())))\n",
    "print(\"Most common words: \"+str(vectorizer.get_feature_names_out()[:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2044260x49323 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8830254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_vector = vectorizer.transform(train_X)\n",
    "train_X_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"sag\").fit(train_X_vector, train_y)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
